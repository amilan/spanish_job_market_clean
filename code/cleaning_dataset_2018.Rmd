---
title: "Cleaning Spanish Job Market Dataset"
author: "Antonio Milán Otero"
date: '`r format(Sys.Date(),"%e de %B %Y")`'
output:
  html_document:
    toc: yes
  pdf_document:
    latex_engine: xelatex
    toc: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r load_libraries, include=FALSE}
library(knitr)
library(lubridate)
library(VIM)
library(stringr)
library(psych)
library(ggplot2)
# for ploting correlations
library(ellipse)
library(plyr)
library(gdata)
```

\newpage
# 1. Descripció del dataset

Aquest dataset conté informació sobre ofertes laborals trobades a la web proporcionada per l'estat Espanyol per a tal propòsit: <https://www.empleate.gob.es/empleo/#/>. Les ofertes contingudes tenen data d'entre Juny de 2016 i Novembre del 2018, sent la gran majoria de les ofertes del 2018.

Aquest dataset prové de la pràctica anterior, en la qual, no vaig prestar gens d'atenció a la neteja de les dades, donant com a resultat un dataset molt brut. Això es va fer a propòsit per tal de poder aprofitar el dataset en aquesta pràctica.

Per tal de donar a entendre una mica més el contingut d'aquest dataset, passarem a inspeccionar algunes de les seves característiques.

Comencem carregant les dades:

```{r}
offers <- read.csv("../data/offers_dataset.csv")
head(offers)
```


```{r}
features_length <- length(offers)
df_length <- length(offers$categoria)
sprintf("Dataset amb %d característiques i %d registres",
        features_length, df_length)
```

Com podem veure, tenim 40534 registres i 94 característiques, moltes de les quals no ens seran d'utilitat. Podríem mirar ara quines son aquestes 94 variables.

```{r}
names(offers)
```

Veiem també que tenim moltes variables que estan duplicades o que no ens proporcionaran informació necessària per als nostres estudis. Podríem consultar més detalls d'aquest dataset amb la següent comanda, que no executarem per tal d'afavorir la lectura d'aquest document:

```{r eval=FALSE}
summary(offers)
```

Veiem que per tal d'estudiar els salaris ofertats, tenim dues característiques a estudiar: salarioMax i salarioMin.

```{r}
sal_min_mean <- mean(offers$salarioMin, na.rm = TRUE)
sal_min_sd <- sd(offers$salarioMin, na.rm = TRUE)
sprintf("Mitjana del salari mínim de les ofertes: %f,", sal_min_mean)
sprintf("    amb una desviació estàndard de: %f",sal_min_sd)
```

```{r}
sal_max_mean <- mean(offers$salarioMax, na.rm = TRUE)
sal_max_sd <- sd(offers$salarioMax, na.rm = TRUE)
sprintf("Mitjana del salari màxim de les ofertes: %f,", sal_max_mean)
sprintf("    amb una desviació estàndard de: %f",sal_max_sd)
```

Amb tota aquesta informació, podem enumerar quines son les preguntes que volem respondre:

1. Quines regions d'Espanya generen més ofertes de treball?
2. Podem fer prediccions sobre salaris mínims i màxims?
3. Estudi sobre els salaris en relació a les 5 regions que generen més ofertes. Tenim regions amb salari mínim superior a la resta? I a la categoria d'informàtica i telecomunicacions?

A la pràctica anterior enumeràvem també les següents idees que deixarem obertes per a possibles futurs estudis i que __no__ formen part dels objectius d'aquest treball:

- A on trobem un major salari?
- Quin tipus de professional és el més sol·licitat a Espanya (durant el període de mostreig)?
- Analitzar els diferents requeriments professionals que tenen les diferents autonomies d'Espanya.
- Identificar el tipus i la qualitat del treball actual al país.
- Analitzar les regions amb més i menys ofertes de treball.
- Analitzar la distribució de les diferents professions en funció de la regió.
- Ajudar a la creació d’un pla per potenciar el mercat laboral basat en el coneixement obtingut a través de les dades.

\newpage
# 2. Integració i selecció de les dades d'interès a analitzar

Per aquest apartat ja es va crear un script python que s'encarregava de compilar les dades obtingudes en diferents dies. La idea darrera d'aquest script era la de recol·lectar totes les dades disponibles a la web en una primera passada, i desprès anar actualitzant el dataset agafant dades diàries i agrupant-les sota el mateix fitxer .csv

Per tant, en aquest apartat considero que no haig de fer més que el ja s'ha fet fins a la data.

El script es pot trobar en la següent URL:
[https://github.com/amilan/spanish_job_market/blob/master/src/dataset_merge.py]

També tinc en compte, que la web oficial de la qual es va extreure les dades, ja recopila aquestes dades de diferent fonts, així doncs, no considero que sigui necessari la integració de dades de diferents fonts, ja que aquesta ha estat realitzada anteriorment.

Per tot això, en aquest apartat només seleccionarem les dades necessàries per als nostres estudis.

Hem de tenir en compte, que a la pràctica anterior hem vaig limitar a agafar totes les dades possibles i a posar-les en un fitxer .csv.
Aquestes dades provenien d'una base de dades NoSQL, ja que vaig detectar que amb les mateixes crides, podíem obtenir dades amb diferents esquemes (schemaless). Així doncs, farem una selecció de les dades que utilitzarem i eliminarem així dades no necessàries o repetides.

Començarem seleccionant les dades d'interès. Recordem que la meva intenció es la de fer un estudi sobre els salaris mínims i màxims de les ofertes de treball a Espanya i en concret a les comunitats autònomes que més ofertes generen. Tot i així, enfocaré aquest primer pas de neteja amb una mirada més amplia i afegiré algunes característiques extra que hem puguin ser d'utilitat en futures revisions o expansions d'aquest treball. Guardaré aquetes dades netejades en un nou fitxer .csv i després faré una segona neteja per tal de quedar-me només amb les dades d'interès per aquest treball.

Primerament, comprovarem que només tenim dades d'ofertes realitzades a Espanya.

```{r}
levels(offers$paisS)
```

Comprovem dues coses, que tenim ofertes d'Espanya i també al Congo, i que tenim un problema de codificació de caràcters, ja que ens troba el país d'Espanya en tres factors diferents. Com que només volem utilitzar les dades de les ofertes a Espanya, podem seleccionar totes les que no siguin al Congo i desprès eliminar aquesta columna.

Podem corregir les dades errònies de país:

```{r}
offers$paisS <- sub("ESPAÃ‘A", "ESPAÑA", offers$paisS)
offers$paisS <- sub("ESPA��A", "ESPAÑA", offers$paisS)
levels(factor(offers$paisS))
```

També podríem haver canviat la codificació dels caràcters, com veurem més endavant.

Seleccionem ara només les ofertes a Espanya.

```{r}
offers <- subset(offers, paisS == "ESPAÑA")
levels(factor(offers$paisS))
# paisS es ara del tipus chr, hauríem de convertirla de nou a factor
offers$paisS <- factor(offers$paisS)
```

```{r}
class(offers$paisS)
```

Seguidament, eliminarem les columnes que ofereixen informació duplicada. Ens quedarem amb les característiques:

- categoriaF
- comunidadF
- educacionF
- fechaCreacion
- jornadaF
- provinciaS
- salarioMax
- salarioMin
- subcategoriaS

```{r}
selected_features <- c("categoriaF", "comunidadF", "educacionF",
                       "fechaCreacion", "jornadaF", "provinciaS",
                       "salarioMax", "salarioMin", "subcategoriaS")
offers <- offers[selected_features]
head(offers)
```

\newpage
# 3. Neteja de les dades

Com que ens hem adonat abans que hi teníem problemes de codificació amb els strings, lo primer que farem serà corregir aquests problemes. Cal destacar que per tal d'afavorir la lectura del document, no mostrarem tots els factors de les variables, només els sis primers.


```{r}
head(levels(offers$comunidadF))
```

```{r}
offers$comunidadF <- sub("ARAGÃ“N", "ARAGÓN", offers$comunidadF)
offers$comunidadF <- sub("CASTILLA Y LE��N", "CASTILLA Y LEÓN", offers$comunidadF)
offers$comunidadF <- sub("CASTILLA Y LEÃ“N", "CASTILLA Y LEÓN", offers$comunidadF)
offers$comunidadF <- sub("CATALU��A", "CATALUÑA", offers$comunidadF)
offers$comunidadF <- sub("CATALUÃ‘A", "CATALUÑA", offers$comunidadF)
offers$comunidadF <- sub("ANDALUCÃ�A", "ANDALUCÍA", offers$comunidadF)
offers$comunidadF <- sub("REGI��N DE MURCIA", "REGIÓN DE MURCIA", offers$comunidadF)
offers$comunidadF <- sub("REGIÃ“N DE MURCIA", "REGIÓN DE MURCIA", offers$comunidadF)
offers$comunidadF <- sub("PAÃ�S VASCO", "PAÍS VASCO", offers$comunidadF)
offers$comunidadF <- sub("Sin especificar", "", offers$comunidadF)
offers$comunidadF <- factor(offers$comunidadF)
head(levels(offers$comunidadF))
```

```{r}
length(levels(offers$comunidadF))
```

Veiem que en aquest cas podem tenir valor buit ("") o __sin especificar__. Ens interessa canviar el valor buit per "Unknown", ja que sabem que la oferta ha d'estar ubicada en alguna comunitat, però no sabem en quina. Aquest valor ens facilitarà futures interpretacions dels resultats.

```{r}
# Convertim els valors buits en NA per reconvertir-los a Unknown.
offers$comunidadF <- NAToUnknown(unknownToNA(offers$comunidadF, unknown = ""), unknown = "Unknown")
head(levels(offers$comunidadF))

length(levels(offers$comunidadF))
```

```{r}
head(levels(offers$categoriaF))
```

En comptes de corregir un a un, transformarem les dades al format latin1.

```{r}
# convertim les dades a encoding latin1
offers$categoriaF <- factor(iconv(offers$categoriaF, to = "latin1"))
length(levels(offers$categoriaF))

# Convertim els valors buits en NA per reconvertir-los a Unknown.
offers$categoriaF <- NAToUnknown(unknownToNA(offers$categoriaF, unknown = ""), unknown = "Unknown")
head(levels(offers$categoriaF))
length(levels(offers$categoriaF))
```

```{r}
head(levels(offers$provinciaS))
```

Podem veure que Guipúzcua està repetida degut a la mala codificació.

```{r}
# convertim les dades a encoding latin1
offers$provinciaS <- factor(iconv(offers$provinciaS, to = "latin1"))
head(levels(offers$provinciaS))
length(levels(offers$provinciaS))
```

```{r}
# Convertim els valors buits en NA per reconvertir-los a Unknown.
offers$provinciaS <- NAToUnknown(unknownToNA(offers$provinciaS, unknown = ""), unknown = "Unknown")
head(levels(offers$provinciaS))
length(levels(offers$provinciaS))
```

```{r}
levels(offers$jornadaF)
```

```{r}
# Convertim els valors buits en NA per reconvertir-los a Unknown.
offers$jornadaF <- NAToUnknown(unknownToNA(offers$jornadaF, unknown = ""), unknown = "Unknown")
levels(offers$jornadaF)
```

```{r}
# convertim les dades a encoding latin1
offers$subcategoriaS <- factor(iconv(offers$subcategoriaS, to = "latin1"))
head(levels(offers$subcategoriaS))
length(levels(offers$subcategoriaS))
```

```{r}
# Convertim els valors buits en NA per reconvertir-los a Unknown.
offers$subcategoriaS <- NAToUnknown(unknownToNA(offers$subcategoriaS, unknown = ""), unknown = "Unknown")
head(levels(offers$subcategoriaS))
length(levels(offers$subcategoriaS))
```

```{r}
# convertim les dades a encoding latin1
offers$educacionF <- factor(iconv(offers$educacionF, to = "latin1"))
head(levels(offers$educacionF))
```

Tot i la conversió, encara tenim algun cas que no s'ha codificat correctament. El corregirem manualment.

```{r}
offers$educacionF <- sub("Diplomado o Ingeniero TÃ©cnico",
                         "Diplomado o Ingeniero Técnico",
                         offers$educacionF)
offers$educacionF <- sub("Sin especificar", "",
                         offers$educacionF)
offers$educacionF <- factor(offers$educacionF)
head(levels(offers$educacionF))
```

```{r}
length(levels(offers$educacionF))
# Convertim els valors buits en NA per reconvertir-los a Unknown.
offers$educacionF <- NAToUnknown(unknownToNA(offers$educacionF,
                                             unknown = ""),
                                 unknown = "Unknown")
head(levels(offers$educacionF))
length(levels(offers$educacionF))
```

## Les dades contenen zeros o elements buits? Com gestionaries aquests casos?

Com hem vist anteriorment, tenim dades amb element buits en les característiques del tipus factor. Hem convertit també les dades amb valors __sin especificar__ en valor buit, ja que aquest, per exemple, representa millor que la oferta està situada a una localització, però no sabem a on. Un cop feta aquesta transformació, hem aplicat una altra per convertir tots els valors buits en "Unknown", ja que aquest valor ens facilitarà més la comprensió dels resultats finals.

Passem ara a mirar si tenim elements nulls (NA).

```{r}
sapply(offers, function(x)(sum(is.na(x))))
```

```{r}
length(offers$salarioMax)
```

Passem ara a netejar les característiques numèriques. Veiem que aproximadament una quarta part de les dades disposen de valors de salari mínim i màxim. Aquests ens podrien ser suficient per al nostres estudi, sempre i quan tinguem suficient casos d'estudi per a les diferents regions.

Llavors, ens quedarem amb les dades que tenen un salari màxim, ja que aquest grup és menor que els que tenen salari mínim, i descartarem la resta.

```{r}
offers <- subset(offers, !is.na(offers$salarioMax))
```

Comprovem que ja no tenim cap valor NA.

```{r}
sapply(offers, function(x)(sum(is.na(x))))
```

Com que hi ha menys dades amb salari màxim que mínim, podríem haver seguit alguna de les següents estratègies:
- Descartar les dades sense salari màxim. Això reduiria molt el nombre de dades, però encara tindríem prou per al estudi que volem realitzar. Aquesta ha estat la estratègia seguida.
- Imputar dades utilitzant KNN. Amb aquesta estratègia podríem obtenir els valors en funció de les dades veïnes. El problema amb aquesta estratègia es que estaríem imputant aproximadament tres quartes parts de les nostres dades, la qual cosa ens portaria a problemes d'anàlisi posterior. Aquesta estratègia la vaig provar en versions diferents d'aquest treball, obtenint resultats erronis.
- Imputar els valors en funció de la mitjana poblacional de la mostra.

En cas de voler imputar els valors mitjançant l'algoritme KNN ho faríem de la següent manera.

```{r, eval=FALSE}
offers$salarioMax <- kNN(offers)$salarioMax
sapply(offers, function(x)(sum(is.na(x))))
```

Seguidament podríem comprovar si les nostres dades tenen el tipus que desitgem.

```{r}
sapply(offers, function(x)(class(x)))
```

Veiem que haurem de tractar el format de la característica fechaCreacion. En aquest moment, tenim la data com a un string amb el format: anys, mes, dia, hora. En el nostre cas, només amb l'any, mes i dia en tindrem prou. A més, haurem de donar-li el tipus de date type.

```{r}
offers$fechaCreacion <- as.Date(gsub("T\\d*:\\d*:\\d*Z",
                                     "",
                                     offers$fechaCreacion))
sapply(offers, function(x)(class(x)))
```

```{r}
summary(offers)
```

Per últim, podem canviar el nombre de les característiques per que tinguin una mica més de sentit i guardem les dades en un nou fitxer csv.

```{r}
names(offers)
```

```{r}
final_names <- c("Categoria", "Comunidad", "Educacion",
                 "FechaCreacion", "TipoJornada",
                 "Provincia", "SalarioMax", "SalarioMin",
                 "SubCategoria")
names(offers) <- final_names
head(offers)
```

Ara que tenim la variable FechaCreacion com a tipus Date, podríem filtrar les ofertes i quedar-nos només amb les publicades al 2018.

```{r}
offers <- subset(offers, FechaCreacion >= "2018-01-01")
```

Després de fer aquesta neteja, encara podríem comprovar si les nostres dades son consistents. Per fer això podríem mirar si tenim ofertes en les que el salari mínim sigui major que el salari màxim, i de ser així, eliminar-les del nostre dataset.

```{r}
length(subset(offers, SalarioMax < SalarioMin)$SalarioMax)
```

Veiem que efectivament, tenim ofertes amb dades inconsistents. Procedirem doncs a eliminar-les.

```{r}
offers <- subset(offers, SalarioMax >= SalarioMin)
```

En aquest punt, ens adonem que hi ha un tipus de registres en els quals tenim 0 a salari mínim i màxim, lo que vol dir que aquestes ofertes no han introduït un valor real en quant als salaris, o bé son ofertes de pràctiques no remunerades. Ninguna d'aquestes opcions les volem contemplar en el nostre estudi, així que com tenim dades suficients, podem prescindir d'aquestes.

```{r}
offers <- subset(offers, !(SalarioMin == 0 & SalarioMax == 0))
```

Finalment, podríem exportar el nostre conjunt de dades netejat.

```{r}
write.csv(offers, "../data/spanish_job_offers_clean.csv")
```

## Identificació i tractament de valors extrems.

Donem ara un cop d'ull a les dades per tal d'identificar valors extrems.

```{r}
boxplot(offers$SalarioMin)
```

```{r}
boxplot(offers$SalarioMax)
```

```{r}
boxplot(offers$SalarioMin ~ offers$Comunidad, las=2, cex.axis= 0.50)
```

```{r}
boxplot(offers$SalarioMax ~ offers$Comunidad, las=2, cex.axis= 0.50)
```

Com a comprovació extra, podem mirar si existeixen valors extrems al filtrar per la categoria: Informàtica/telecomunicacions. 

```{r}
boxplot(subset(offers, Categoria == "INFORMÁTICA/TELECOMUNICACIONES"), las=2, cex.axis= 0.60)
```

Seguidament, podem veure també quins son els valors extrems que trobem a les nostres dades.

```{r}
boxplot.stats(offers$SalarioMin)$out
```

```{r}
boxplot.stats(offers$SalarioMax)$out
```

Veiem que tenim valors extrems tant en els salaris màxims com en els mínims. En el cas dels salaris mínims, son valor raonables, i crec que els hauríem de deixar tal qual son. En canvi, trobem dos valors extrems molt curiosos, que semblen ser alguna mena de valor prefixat per a no donar un límit superior. En aquest cas, ja que son només dos valors i tenim suficient dades per al nostre estudi, considero que lo millor seria treure les dades corresponents. Així doncs, ho farem de la següent manera.

```{r}
subset(offers, SalarioMax == 9999999)
```

```{r}
offers <- subset(offers, !(SalarioMax==9999999))
```

```{r}
offers$SalarioMin <- as.numeric(offers$SalarioMin)
offers$SalarioMax <- as.numeric(offers$SalarioMax)
boxplot(offers$SalarioMax ~ offers$Comunidad, las=2, cex.axis= 0.50)
```

Veiem que els valors extrems que tenim ara son més raonables, i considero que els podríem deixar tal qual.

\newpage
# 4. Anàlisi de les dades
## Selecció dels grups de dades que es volen analitzar/comparar

Per al nostre estudi ens interessen les dades totals dels salaris màxims i mínims, però també estudiarem les característiques d'aquests salaris ofertats en les 4 comunitats autònomes amb més ofertes.

```{r}
barplot(sort(summary(offers$Comunidad)), horiz = TRUE, las=2, cex.names = 0.30)
```

Amb aquest gràfic ja podem donar resposta a la primera de les preguntes plantejades: Quines regions d'Espanya generen més ofertes de treball?

Podem veure que les 5 primeres regions amb més ofertes de treball son: __Madrid, Catalunya, Andalusia, Comunitat Valenciana i Galicia__.

Creem doncs els grups a estudiar.

```{r}
offers_mad <- subset(offers, Comunidad=="MADRID")
offers_cat <- subset(offers, Comunidad=="CATALUÑA")
offers_and <- subset(offers, Comunidad=="ANDALUCÍA")
offers_val <- subset(offers, Comunidad=="COMUNIDAD VALENCIANA")
offers_gal <- subset(offers, Comunidad=="GALICIA")
```


## Comprovació de la normalitat i homogeneïtat de la variància.

### Comprovació de la Normalitat

Comprovarem ara si les nostres variables d'interès pertanyen a una distribució normal. Començarem amb una inspecció visual als salaris mínims i màxims.

```{r}
qqnorm(offers$SalarioMax, main = "Normal Q-Q Plot for SalarioMax")
qqline(offers$SalarioMax)
```

```{r}
qqnorm(offers$SalarioMin, main = "Normal Q-Q Plot for SalarioMin")
qqline(offers$SalarioMin)
```

Veiem que tant els salaris mínims com màxims no s'ajusten gaire bé a la normalitat. Mirarem ara com es comporten els grups a estudiar.

```{r}

comunity_names <- c("Madrid", "Cataluña", "Andalucía", "Valencia", "Galicia")
comunity_df_list <- list(offers_mad, offers_cat, offers_and, offers_val, offers_gal)
i <- 1
layout(matrix(c(1,2,3,4,5),2,2))
for(data in comunity_df_list){
  qqnorm(data$SalarioMax, main=paste("Normal Q-Q Plot for", comunity_names[i]))
  qqline(data$SalarioMax)
  i<-i+1
}
```

Veiem a les gràfiques que tampoc s'ajusten gairebé a la normalitat.

Igual que a l'apartat anterior, podem comprovar ara si la distribució es normal un cop filtrades les ofertes per a la categoria d'informàtica/telecomunicacions.

```{r}
qqnorm(subset(offers, Categoria == "INFORMÁTICA/TELECOMUNICACIONES")$SalarioMin)
qqline(subset(offers, Categoria == "INFORMÁTICA/TELECOMUNICACIONES")$SalarioMin)
shapiro.test(subset(offers, Categoria == "INFORMÁTICA/TELECOMUNICACIONES")$SalarioMin)
```

Veiem que tampoc s'ajusten gairebé a la normalitat.

Podríem també realitzar els càlculs mitjançant un test de Shapiro-Wilk.

```{r}
shapiro.test(offers$SalarioMax)
```

```{r}
shapiro.test(offers$SalarioMin)
```

Veiem que els resultats dels tests ens ofereixen les mateixes conclusions, i es que no tenim una distribució normal per aquestes dues variables.

Passem ara a comprovar també la normalitat mitjançant el mateix test sobre els salaris mínims i màxims de les ofertes publicades a les 5 regions amb més ofertes.

```{r}
salarioMax_pvalues <- numeric(5)
i <- 1

for(data in comunity_df_list){
  p_val <- shapiro.test(data$SalarioMax)
  salarioMax_pvalues[i] <- p_val$p.value
  i <- i+1
}
```

Fem el mateix test per al salari mínim.

```{r}
salarioMin_pvalues <- numeric(5)
i <- 1

for(data in comunity_df_list){
  p_val <- shapiro.test(data$SalarioMin)
  salarioMin_pvalues[i] <- p_val$p.value
  i <- i+1
}
```

I mostrem els resultats en la següent taula.

```{r}
salaries_pvalues <- cbind(pval_min=salarioMin_pvalues, pval_max=salarioMax_pvalues)
rownames(salaries_pvalues) <- comunity_names
salaries_pvalues
```

En tots els casos veiem que el valor de p_value no supera el 0.05, amb la qual cosa no passen el test de normalitat, es a dir, no segueixen una distribució normal.

Un cop més, com a cas extra, podríem veure com es comporta el conjunt de dades per a la categoria d'informàtica/telecomunicacions.

```{r}
shapiro.test(subset(offers, Categoria == "INFORMÁTICA/TELECOMUNICACIONES")$SalarioMin )
shapiro.test(subset(offers, Categoria == "INFORMÁTICA/TELECOMUNICACIONES")$SalarioMax )
```

Veiem que en aquest cas tampoc tenim un p-value superior a 0.05, amb la qual cosa podem dir que tampoc segueix una distribució normal.

### Homogeneïtat de la Variància

Seguidament podríem mirar la homogeneïtat de la variància. Per a tal efecte, podríem aplicar un test de Fligner-Killeen.

```{r}
fligner.test(SalarioMin ~ SalarioMax, data=offers )
```

```{r}
fligner.test(SalarioMax ~ SalarioMin, data=offers )
```

Com que el valor de p_value es menor que 0.05, no podem acceptar la hipòtesi nul·la de que les variàncies son homogènies. Això es compleix en tots dos casos.

Fem ara els mateixos tests per a les diferents regions.

```{r}
salarioMin_vector <- numeric(5)
i <- 1

for(data in comunity_df_list){
  p_val <- fligner.test(SalarioMin ~ SalarioMax, data=data)
  salarioMin_vector[i] <- p_val$p.value
  i <- i+1
}
```

```{r}
salarioMax_vector <- numeric(5)
i <- 1
for(data in comunity_df_list){
  p_val <- fligner.test(SalarioMax ~ SalarioMin, data=data)
  salarioMax_vector[i] <- p_val$p.value
  i <- i+1
}
```

Podem crear una taula per visualitzar millor els resultats


```{r}
sal_results <- cbind(pval_min=salarioMin_vector, pval_max=salarioMax_vector, deparse.level = 2)
rownames(sal_results) <- comunity_names
sal_results
```

Amb aquests resultats podem veure que no tenim homogeneïtat a les variables Salari{Min,Max} i tampoc a les mateixes variables per regions a estudiar amb una única excepció, la variable de salari mínim a la comunitat valenciana.

Com a la resta de la pràctica, podem mirar com es comporta el conjunt de dades un cop filtrat per la categoria d'informàtica i telecomunicacions.

```{r}
fligner.test(SalarioMin ~ SalarioMax, data=subset(offers, Categoria == "INFORMÁTICA/TELECOMUNICACIONES") )
```

Veiem que es comporta d'igual manera i que tampoc hi ha homogeneïtat de la variància.

## Aplicació de proves estadístiques per comparar els grups de dades.

### Correlacions

Lògicament, la correlació del salari mínim i màxim ha de ser positiva, en la que a major salari mínim tenim també un major salari màxim. De totes maneres, per il·lustrar aquesta relació, podem calcular el valor de correlació d'aquestes dues variables.

```{r}
cor_matrix <- cor(offers$SalarioMin, offers$SalarioMax)
round(cor_matrix, 2)
```

```{r}
pairs(~SalarioMin+SalarioMax,data=offers,
   main="Simple Salary Scatterplot Matrix")
```

Veiem que el coeficient de correlació entre les variables de salari mínim i màxim s'aproxima molt a 1, donant-nos així el resultat esperat, es a dir, que hi existeix correlació.

També podem comprovar aquesta relació a la gràfica d'amunt, a on es mostra gràficament aquesta correlació entre salari mínim i màxim.

Podríem comprovar ara les mateixes correlacions per a les regions que estem analitzant.

```{r fig.width=3, fig.height=3}
cor_vector <- numeric(5)
i <- 1

layout(matrix(c(1,2,3,4,5),1,1))
for(data in comunity_df_list){
  cor_matrix <- cor(data$SalarioMin, data$SalarioMax)
  cor_vector[i] <- round(cor_matrix, 2)
  pairs(~SalarioMin+SalarioMax,data=data,
        main=paste("Salary Scatterplot for",
                   comunity_names[i]))
  i <- i+1
}

cor_table <- cbind(correlation=cor_vector)
rownames(cor_table) <- comunity_names
cor_table
```

Podem veure tant amb els valors obtinguts com a les gràfiques, que aquesta correlació existeix també quan analitzem els conjunts de dades per comunitats. Cal comentar també que a la comunitat de Madrid es a on trobem un valor de correlació inferior a la resta.

```{r}
pairs(~SalarioMin+SalarioMax,data=subset(offers, Categoria == "INFORMÁTICA/TELECOMUNICACIONES"),
   main="Simple Salary Scatterplot Matrix")
```

D'igual manera, veiem que existeix una correlació en aquestes variables quan filtrem per categoria Informàtica/telecomunicaciones.

### Regressió Lineal

Podríem passar ara a crear diferents models de regressió lineal per tal de predir els salaris màxims.

Comencem amb un model en el que intentarem obtenir el salari màxim en funció del mínim i la comunitat autónoma de la oferta.


```{r}

# Creem el nostre model lineal
model_1 <- lm(SalarioMax ~ SalarioMin + Comunidad, data=offers)
summary(model_1)$r.squared
```

Podem veure que la qualitat del model obtingut no es massa bona amb un R squared de 0.582. Tot i així, amb aquest model podríem fer prediccions com les següents.

```{r}
# Salari Màxim si sabem que el mínim es 20000 i l'oferta es a Catalunya.
data_pred_cat <- data.frame(Comunidad="CATALUÑA", SalarioMin=20000)
data_pred_mad <- data.frame(Comunidad="MADRID", SalarioMin=20000)
data_pred_and <- data.frame(Comunidad="ANDALUCÍA", SalarioMin=20000)
data_pred_val <- data.frame(Comunidad="COMUNIDAD VALENCIANA", SalarioMin=20000)
data_pred_gal <- data.frame(Comunidad="GALICIA", SalarioMin=20000)
```

```{r}
predictions_model1_vector <- numeric(5)
i <- 1

for(data_pred in list(data_pred_mad, data_pred_cat, data_pred_and, data_pred_val, data_pred_gal)){
  prediction <- predict(model_1, data_pred)
  predictions_model1_vector[i] <- prediction
  i <- i+1
}

pred_m1_table <- rbind(madrid=predictions_model1_vector[1],
                       cataluña=predictions_model1_vector[2],
                       andalucia=predictions_model1_vector[3],
                       valencia=predictions_model1_vector[4],
                       galicia=predictions_model1_vector[5])
colnames(pred_m1_table) <- c("Salary_prediction_model_1")
pred_m1_table
```

Podem mirar si obtenim un model millor utilitzant els dataset amb les regions amb més ofertes de treball.

```{r}

# Creem els nostres models de regressió lineal
model_cat <- lm(SalarioMax ~ SalarioMin, data=offers_cat)
model_mad <- lm(SalarioMax ~ SalarioMin, data=offers_mad)
model_and <- lm(SalarioMax ~ SalarioMin, data=offers_and)
model_val <- lm(SalarioMax ~ SalarioMin, data=offers_val)
model_gal <- lm(SalarioMax ~ SalarioMin, data=offers_gal)

r_square_coms <- rbind(madrid=summary(model_mad)$r.squared,
                       cataluña=summary(model_cat)$r.squared,
                       andalucia=summary(model_and)$r.squared,
                       valencia=summary(model_val)$r.squared,
                       galicia=summary(model_gal)$r.squared)
colnames(r_square_coms) <- c("R squared")
r_square_coms
```

En aquest cas, la qualitat del nostre model es bastant alta, amb lo qual, les nostres prediccions seran més fiables.

Comprovem també que el model de regressió lineal per a la comunitat de Madrid té una qualitat molt més baixa, això es degut a que, com hem vist abans, el coeficient de correlació entre el salari mínim i màxim es més baix que a la resta. Això ens donarà unes pitjors prediccions per aquest conjunt de dades.

Mirem ara quina seria la predicció del salari màxim per aquest nou model.

```{r}
data_pred <- data.frame(SalarioMin=20000)

predictions_vector <- numeric(5)
i <- 1

for(model_lm in list(model_mad,model_cat,model_and,model_val,model_gal)){
  prediction <- predict(model_lm, data_pred)
  predictions_vector[i] <- prediction
  i <- i+1
}

pred_table <- rbind(madrid=predictions_vector[1],
                    cataluña=predictions_vector[2],
                    andalucia=predictions_vector[3],
                    valencia=predictions_vector[4],
                    galicia=predictions_vector[5])
colnames(pred_table) <- c("Salary_prediction")
pred_table
```

```{r}
ggplot() +
  geom_point(data = as.data.frame(pred_table),
             aes(comunity_names,
                 Salary_prediction,
                 colour='Modelo por Comunidades'),
             size = 3) +
  geom_point(data = as.data.frame(pred_m1_table),
             aes(comunity_names,
                 Salary_prediction_model_1,
                 colour = 'Modelo 1'),
             size = 3) +
  labs(x="Comunidades Autónomas", y="Salario Máximo",
       title="Prediccion Salario Máximo") + 
  theme(legend.position = "right")
```

Veiem que amb aquests models podem fer prediccions sobre quant podria arribar a ser el salari màxim en funció del mínim, la comunitat i la categoria de la oferta.

Podríem mirar ara si som capaços de predir el salari màxim sense fer ús del salari mínim.

```{r}

# Creem el nostre model lineal
model_no_salmin <- lm(SalarioMax ~ Categoria + Comunidad + Educacion + TipoJornada + FechaCreacion, data=offers)
summary(model_no_salmin)$r.squared
```

Veiem que la qualitat del model obtingut és molt baixa, amb la qual cosa, si fem ús d'aquest model, les nostres prediccions serien molt poc fiables.

Per últim, podríem fer les mateixes operacions filtrant només per ofertes d'informàtica i telecomunicacions.

```{r}
# Creem els nous models de regressió lineal
model_cat_cat <- lm(SalarioMax ~ SalarioMin + Categoria, data=offers_cat)
model_mad_cat <- lm(SalarioMax ~ SalarioMin + Categoria, data=offers_mad)
model_and_cat <- lm(SalarioMax ~ SalarioMin + Categoria, data=offers_and)
model_val_cat <- lm(SalarioMax ~ SalarioMin + Categoria, data=offers_val)
model_gal_cat <- lm(SalarioMax ~ SalarioMin + Categoria, data=offers_gal)

# Creem una taula amb els valors de r squared
r_square_coms_cat <- rbind(madrid=summary(model_mad_cat)$r.squared,
                       cataluña=summary(model_cat_cat)$r.squared,
                       andalucia=summary(model_and_cat)$r.squared,
                       valencia=summary(model_val_cat)$r.squared,
                       galicia=summary(model_gal_cat)$r.squared)
colnames(r_square_coms_cat) <- c("R squared")
#r_square_coms_cat

# Creem el nostre dataframe per fer prediccions
data_pred_cat <- data.frame(SalarioMin=20000, Categoria="INFORMÁTICA/TELECOMUNICACIONES")

predictions_vector_cat <- numeric(5)
i <- 1

# Fem les prediccions
for(model_lm_cat in list(model_mad_cat,
                         model_cat_cat,
                         model_and_cat,
                         model_val_cat,
                         model_gal_cat)){
  prediction_cat <- predict(model_lm_cat, data_pred_cat)
  predictions_vector_cat[i] <- prediction_cat
  i <- i+1
}

# Recollim resultats en una taula
pred_table_cat <- rbind(madrid=predictions_vector_cat[1],
                    cataluña=predictions_vector_cat[2],
                    andalucia=predictions_vector_cat[3],
                    valencia=predictions_vector_cat[4],
                    galicia=predictions_vector_cat[5])
colnames(pred_table_cat) <- c("Salary_prediction_cat")
pred_table_cat <- cbind(R_squared=r_square_coms_cat, salary_predictions_cat=pred_table_cat)
pred_table_cat
```

Veiem que la qualitat dels models son una mica millors en aquest cas.

Per últim, podem comparar gràficament tots els resultats obtinguts en les nostres prediccions.

```{r}
ggplot() +
  geom_point(data = as.data.frame(pred_table),
             aes(comunity_names,
                 Salary_prediction,
                 colour='Model per Comunitats'),
             size = 3) +
  geom_point(data = as.data.frame(pred_m1_table),
             aes(comunity_names,
                 Salary_prediction_model_1,
                 colour = 'Model 1'),
             size = 3) +
  geom_point(data = as.data.frame(pred_table_cat),
             aes(comunity_names,
                 Salary_prediction_cat,
                 colour = 'Model per Categoria Informàtica/Telecom.'),
             size = 3) +
  labs(x="Comunidades Autónomas", y="Salario Máximo",
       title="Prediccion Salario Máximo") + 
  theme(legend.position = "right")
```

Resulta interessant veure com les nostres prediccions fetes amb el primer model (amb una qualitat inferior) ens dona com a resultat unes prediccions amb un rang bastant similar, mentres que en els models més especialitats s'observen majors diferències entre regions.

També es interessant veure com les nostres prediccions per a la categoria d'informàtica i telecomunicacions ens donen diferències positives molt grans per a Catalunya i Madrid, i negatives per a la resta de regions.

### Contrasts d'Hipòtesi

Seguidament podríem fer un contrast entre regions per tal de donar resposta a la pregunta: a Catalunya es generen ofertes de treball amb un salari mínim superior a la resta d'Espanya?

Per a tal motiu utilitzarem necessitarem preparar el conjunt de dades de mostres de comunitats diferents a Catalunya.

```{r}
offers_no_cat <- subset(offers, !(Comunidad=="CATALUÑA"))
```

Per aquest estudi utilitzarem la següent hipòtesi nul·la i alternativa:

$$H0: \mu_1-\mu_2 = 0$$

$$H1: \mu_1-\mu_2 > 0$$

Farem servir un contrast sobre la diferència de mitjanes. Com que les nostres dues mostres tenen més de 30 observacions, gràcies al teorema del límit central podrem considerar-les com distribucions normals. 

```{r}
t_test_no_cat <- t.test(offers_cat$SalarioMin, offers_no_cat$SalarioMin, alternative = "greater")
t_test_no_cat
```

Com que el p-value es menor que 0.05, podem rebutjar la hipòtesi nul·la a favor de la hipòtesi alternativa, lo que vol dir que podem afirmar que el salari mínim les ofertes de treball a Catalunya sigui més alt que a la resta d'Espanya.

Mirem ara si això es compleix també en la resta de comunitats que volem estudiar.

```{r}
offers_no_mad <- subset(offers, !(Comunidad=="MADRID"))
t_test_no_mad <- t.test(offers_mad$SalarioMin, offers_no_mad$SalarioMin, alternative = "greater")
offers_no_and <- subset(offers, !(Comunidad=="ANDALUCÍA"))
t_test_no_and <- t.test(offers_and$SalarioMin, offers_no_and$SalarioMin, alternative = "greater")
offers_no_val <- subset(offers, !(Comunidad=="COMUNIDAD VALENCIANA"))
t_test_no_val <- t.test(offers_val$SalarioMin, offers_no_val$SalarioMin, alternative = "greater")
offers_no_gal <- subset(offers, !(Comunidad=="GALICIA"))
t_test_no_gal <- t.test(offers_val$SalarioMin, offers_no_gal$SalarioMin, alternative = "greater")
```


```{r}
results_coms <- rbind(t_test_no_mad$p.value, t_test_no_cat$p.value, t_test_no_and$p.value, t_test_no_val$p.value, t_test_no_gal$p.value)
rownames(results_coms) <- comunity_names
colnames(results_coms) <- c("p_values")
results_coms
```

Podem veure que tant a Catalunya com a Madrid, tením p-values menors a 0.05 que es el nostre valor de significació, amb la qual cosa rebutjem les hipòtesis nul·les en favor de les alternatives, i això ens porta a concloure que la mitjana en els salaris mínims de les ofertes de treball a Catalunya i Madrid estàn per sobre de les ofertes a la resta del país. En canvi, a Andalucía, València i Galicia tenim els casos contraris.


Per últim, podem fer el mateix exercici per veure si el salari mínim a la categoria d'informàtica i telecomunicacions es superior a la resta de categories.

```{r}
offers_inf <- subset(offers, (Categoria=="INFORMÁTICA/TELECOMUNICACIONES"))
offers_no_inf <- subset(offers, !(Categoria=="INFORMÁTICA/TELECOMUNICACIONES"))
t_test_inf <- t.test(offers_inf$SalarioMin, offers_no_inf$SalarioMin, alternative = "greater")
t_test_inf
```

Com que també obtenim un valor p-value menor a 0.05, rebutjem l'hipòtesi nul·la en favor de l'alternativa, amb la qual cosa podem dir que els salaris a la categoria d'informàtica i telecomunicacions estàn per sobre de la resta de categories.

\newpage
# 5. Representació dels resultats a partir de taules i gràfiques

Per a una millor comprensió dels resultats, s'han anat afegint diferents taules i gràfiques al llarg d'aquesta pràctica. Com que aquest treball dona resposta a diferents preguntes, considero que el millor lloc per a aquestes gràfiques és al costat dels seus exercicis previs. Per tant, no tornaré a generar-les en aquest apartat, ja que supondria una repetició que no aportaría nova informació.

# 6. Resolució del problema. A partir dels resultats obtinguts, quines són les conclusions? Els resultats permeten respondre al problema?

Les tres preguntes plantejades a l'inici de la pràctica eran les següents:

1. Quines regions d'Espanya generen més ofertes de treball?
2. Podem fer prediccions sobre salaris mínims i màxims?
3. Estudi sobre els salaris en relació a les 5 regions que generen més ofertes. Tenim regions amb salari mínim superior a la resta? I a la categoria d'informàtica i telecomunicacions?

Per tal de respondre a la primera pregunta, hem pogut veure tant gràficament com al sumari de les nostres dades, que les regions amb més ofertes publicades son Madrid, Catalunya, Andalusia, Comunitat Valenciana i Galícia.

Com hem pogut veure al llarg de la pràctica, amb les dades existents som capaços d'elaborar un model predictiu bassat en regressió lineal per tal de predir els salaris màxims (o mínims si volguessim), en funció dels salaris mínims, donant resposta així a la segona pregunta. També hem provat a generar un model de regressió lineal que ens permetés predir el salari màxim en funció d'altres variables que no siguin el salari mínim, però la qualitat d'aquest models son molt dolentes i les seves prediccions no serien molt correctes.

Per últim, per tal de resoldre la tercera pregunta, hem pogut comprovar que de les cinc regions amb més ofertes de treball públicades, a les regions de Catalunya i Madrid trobem salaris mínims més elevats que a la resta del país, mentres que a Andalusia, València i Galícia no passa igual. També dintre d'aquesta pregunta hem observat que els salaris de la categoria d'informàtica i telecomunicacions estàn per sobre de la resta de categories.

\newpage
# 7. Referències

## Bibliografia:

- Dalgaard, Peter (2002). Introductory Statistics with R. Verlang, New York. Springer.
- Jarman, Kristin (2017). The Art of Data Analysis. New Jersey. Wiley.
- Osborne, Jason (2010). Data Cleaning Basics: Best Practices in Dealing with Extreme Scores. North Carolina State. Elsevier.

## Links:

- Quick-R. <https://www.statmethods.net/index.html>
- R-Bloggers. <https://www.r-bloggers.com/>
- Statistical Data Analysis. <https://stat.ethz.ch/R-manual/>
- Cookbook for R. <http://www.cookbook-r.com/>
- Working with Unknown Values.  <https://cran.r-project.org/web/packages/gdata/vignettes/unknown.pdf>
- ggplot2. <https://ggplot2.tidyverse.org/>